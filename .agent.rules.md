# .agent.rules.md

# Celebrate GmbH Agent Rules for TS Projects

> **Version:** v1.0.15
> **Language:** TS
> **Auto-generated file** - Do not edit directly. Generated from base rules + TS-specific rules.
> **Source:** https://github.com/celebrate-gmbh/agent-rules
> **Generated:** 2025-08-19 11:52:18 UTC

<!-- Trigger release v1.0.9 -->

These are the foundational rules for all Celebrate GmbH projects. The base rules are now modularized into separate files that are automatically combined during the build process.


## Purpose

These rules ensure **maintainability**, **safety**, and **developer velocity**.  
- **MUST** rules are enforced via CI and lint/type tooling  
- **SHOULD** rules are strongly recommended and regularly reviewed in PRs
---

## Before Coding

- **BP-1 (MUST)** Ask for clarifying questions if any part of the task is ambiguous.
- **BP-2 (SHOULD)** Draft and validate an approach for non-trivial changes.
- **BP-3 (SHOULD)** If more than one approach exists, list pros/cons explicitly.
---

## While Coding (Common Rules)

- **C-1 (MUST)** Use TDD where practical: scaffold → failing test → implement.
- **C-2 (MUST)** Use domain language when naming functions/methods/classes.
- **C-3 (SHOULD NOT)** Use comments unless explaining non-obvious caveats. Prioritize self-documenting code.
- **C-4 (SHOULD NOT)** Extract functions/methods unless:
  - reused,
  - needed to isolate untestable logic,
  - or they drastically improve readability.
---

## Testing (Common Rules)

- **T-1 (MUST)** Separate unit tests from integration tests.
- **T-2 (SHOULD)** Favor integration tests over mocking.
- **T-3 (SHOULD)** Unit test complex logic (e.g. conditionals, transforms).
---

## Git Commit Hygiene

- **GH-1 (MUST)** Use [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0).
- **GH-2 (SHOULD NOT)** Reference Claude or Anthropic in commits.
- **GH-3 (MUST)** use main instead of master
---

## Function/Method Implementation Checklist

Evaluate every function/method with this list:

1. Is it easy to follow with no mental gymnastics?
2. Does it avoid deep nesting or high cyclomatic complexity?
3. Can common data structures simplify it?
4. Are any parameters unused?
5. Can any type coercion be moved to parameters?
6. Is it testable in isolation or via integration test?
7. Are there hidden unmocked side effects?
8. Try 3 better names. Is the current name still best?

**Refactor only if:**
- Used in >1 place
- Needed for unit testing
- Original function/method requires excessive inline explanation
---

## Test Quality Checklist

Evaluate all tests against this:

1. **SHOULD** parameterize inputs; no magic numbers.
2. **SHOULD NOT** write trivial tests.
3. **SHOULD** match test name to assertion meaning.
4. **SHOULD** compare to known truths, not self-verified outputs.
5. **SHOULD** follow language-specific lint/style rules.
6. **SHOULD** use strong assertions (language-specific equivalents).
7. Test:
   - edge cases
   - realistic input
   - invalid input
   - boundaries
8. Don't test things the type system already enforces.
---

## Documentation

- **D-1 (MUST)** Create and maintain a `/docs` directory with system architecture documentation
- **D-2 (MUST)** Include a mermaid chart with an up-to-date system diagram in `/docs/system-architecture.md`
- **D-3 (MUST)** Add a link to the system architecture diagram in the README
- **D-4 (SHOULD)** Keep documentation in sync with code changes
- **D-5 (SHOULD)** Use mermaid diagrams for visual representations of complex systems
---

## Generating a Product Requirements Document (PRD)

### Goal

To guide an AI assistant in creating a detailed Product Requirements Document (PRD) in Markdown format, based on an initial user prompt. The PRD should be clear, actionable, and suitable for a junior developer to understand and implement the feature.

### Process

1.  **Receive Initial Prompt:** The user provides a brief description or request for a new feature or functionality.
2.  **Ask Clarifying Questions:** Before writing the PRD, the AI *must* ask clarifying questions to gather sufficient detail. The goal is to understand the "what" and "why" of the feature, not necessarily the "how" (which the developer will figure out). Make sure to provide options in letter/number lists so I can respond easily with my selections.
3.  **Generate PRD:** Based on the initial prompt and the user's answers to the clarifying questions, generate a PRD using the structure outlined below.
4.  **Save PRD:** Save the generated document as `prd-[feature-name].md` inside the `/tasks` directory.

### Clarifying Questions (Examples)

The AI should adapt its questions based on the prompt, but here are some common areas to explore:

*   **Problem/Goal:** "What problem does this feature solve for the user?" or "What is the main goal we want to achieve with this feature?"
*   **Target User:** "Who is the primary user of this feature?"
*   **Core Functionality:** "Can you describe the key actions a user should be able to perform with this feature?"
*   **User Stories:** "Could you provide a few user stories? (e.g., As a [type of user], I want to [perform an action] so that [benefit].)"
*   **Acceptance Criteria:** "How will we know when this feature is successfully implemented? What are the key success criteria?"
*   **Scope/Boundaries:** "Are there any specific things this feature *should not* do (non-goals)?"
*   **Data Requirements:** "What kind of data does this feature need to display or manipulate?"
*   **Design/UI:** "Are there any existing design mockups or UI guidelines to follow?" or "Can you describe the desired look and feel?"
*   **Edge Cases:** "Are there any potential edge cases or error conditions we should consider?"

### PRD Structure

The generated PRD should include the following sections:

1.  **Introduction/Overview:** Briefly describe the feature and the problem it solves. State the goal.
2.  **Goals:** List the specific, measurable objectives for this feature.
3.  **User Stories:** Detail the user narratives describing feature usage and benefits.
4.  **Functional Requirements:** List the specific functionalities the feature must have. Use clear, concise language (e.g., "The system must allow users to upload a profile picture."). Number these requirements.
5.  **Non-Goals (Out of Scope):** Clearly state what this feature will *not* include to manage scope.
6.  **Design Considerations (Optional):** Link to mockups, describe UI/UX requirements, or mention relevant components/styles if applicable.
7.  **Technical Considerations (Optional):** Mention any known technical constraints, dependencies, or suggestions (e.g., "Should integrate with the existing Auth module").
8.  **Success Metrics:** How will the success of this feature be measured? (e.g., "Increase user engagement by 10%", "Reduce support tickets related to X").
9.  **Open Questions:** List any remaining questions or areas needing further clarification.

### Target Audience

Assume the primary reader of the PRD is a **junior developer**. Therefore, requirements should be explicit, unambiguous, and avoid jargon where possible. Provide enough detail for them to understand the feature's purpose and core logic.

### Output

*   **Format:** Markdown (`.md`)
*   **Location:** `/tasks/`
*   **Filename:** `prd-[feature-name].md`

### Final Instructions

1. Do NOT start implementing the PRD
2. Make sure to ask the user clarifying questions
3. Take the user's answers to the clarifying questions and improve the PRD
---

## Generating a Task List from a PRD

### Goal

To guide an AI assistant in creating a detailed, step-by-step task list in Markdown format based on an existing Product Requirements Document (PRD). The task list should guide a developer through implementation.

### Output

- **Format:** Markdown (`.md`)
- **Location:** `/tasks/`
- **Filename:** `tasks-[prd-file-name].md` (e.g., `tasks-prd-user-profile-editing.md`)

### Process

1.  **Receive PRD Reference:** The user points the AI to a specific PRD file
2.  **Analyze PRD:** The AI reads and analyzes the functional requirements, user stories, and other sections of the specified PRD.
3.  **Assess Current State:** Review the existing codebase to understand existing infrastructre, architectural patterns and conventions. Also, identify any existing components or features that already exist and could be relevant to the PRD requirements. Then, identify existing related files, components, and utilities that can be leveraged or need modification.
4.  **Phase 1: Generate Parent Tasks:** Based on the PRD analysis and current state assessment, create the file and generate the main, high-level tasks required to implement the feature. Use your judgement on how many high-level tasks to use. It's likely to be about 5. Present these tasks to the user in the specified format (without sub-tasks yet). Inform the user: "I have generated the high-level tasks based on the PRD. Ready to generate the sub-tasks? Respond with 'Go' to proceed."
5.  **Wait for Confirmation:** Pause and wait for the user to respond with "Go".
6.  **Phase 2: Generate Sub-Tasks:** Once the user confirms, break down each parent task into smaller, actionable sub-tasks necessary to complete the parent task. Ensure sub-tasks logically follow from the parent task, cover the implementation details implied by the PRD, and consider existing codebase patterns where relevant without being constrained by them.
7.  **Identify Relevant Files:** Based on the tasks and PRD, identify potential files that will need to be created or modified. List these under the `Relevant Files` section, including corresponding test files if applicable.
8.  **Generate Final Output:** Combine the parent tasks, sub-tasks, relevant files, and notes into the final Markdown structure.
9.  **Save Task List:** Save the generated document in the `/tasks/` directory with the filename `tasks-[prd-file-name].md`, where `[prd-file-name]` matches the base name of the input PRD file (e.g., if the input was `prd-user-profile-editing.md`, the output is `tasks-prd-user-profile-editing.md`).

#### Output Format

The generated task list _must_ follow this structure:

```markdown
### Relevant Files

- `path/to/potential/file1.ts` - Brief description of why this file is relevant (e.g., Contains the main component for this feature).
- `path/to/file1.test.ts` - Unit tests for `file1.ts`.
- `path/to/another/file.tsx` - Brief description (e.g., API route handler for data submission).
- `path/to/another/file.test.tsx` - Unit tests for `another/file.tsx`.
- `lib/utils/helpers.ts` - Brief description (e.g., Utility functions needed for calculations).
- `lib/utils/helpers.test.ts` - Unit tests for `helpers.ts`.

### Notes

- Unit tests should typically be placed alongside the code files they are testing (e.g., `MyComponent.tsx` and `MyComponent.test.tsx` in the same directory).
- Use `npx jest [optional/path/to/test/file]` to run tests. Running without a path executes all tests found by the Jest configuration.

### Tasks

- [ ] 1.0 Parent Task Title
  - [ ] 1.1 [Sub-task description 1.1]
  - [ ] 1.2 [Sub-task description 1.2]
- [ ] 2.0 Parent Task Title
  - [ ] 2.1 [Sub-task description 2.1]
- [ ] 3.0 Parent Task Title (may not require sub-tasks if purely structural or configuration)
```

### Interaction Model

The process explicitly requires a pause after generating parent tasks to get user confirmation ("Go") before proceeding to generate the detailed sub-tasks. This ensures the high-level plan aligns with user expectations before diving into details.

### Target Audience

Assume the primary reader of the task list is a **junior developer** who will implement the feature with awareness of the existing codebase context.
---

## Task List Management

Guidelines for managing task lists in markdown files to track progress on completing a PRD

### Task Implementation
- **One sub-task at a time:** Do **NOT** start the next sub‑task until you ask the user for permission and they say "yes" or "y"
- **Completion protocol:**  
  1. When you finish a **sub‑task**, immediately mark it as completed by changing `[ ]` to `[x]`.
  2. If **all** subtasks underneath a parent task are now `[x]`, follow this sequence:
    - **First**: Run the full test suite (`pytest`, `npm test`, `bin/rails test`, etc.)
    - **Only if all tests pass**: Stage changes (`git add .`)
    - **Clean up**: Remove any temporary files and temporary code before committing
    - **Commit**: Use a descriptive commit message that:
      - Uses conventional commit format (`feat:`, `fix:`, `refactor:`, etc.)
      - Summarizes what was accomplished in the parent task
      - Lists key changes and additions
      - References the task number and PRD context
      - **Formats the message as a single-line command using `-m` flags**, e.g.:

        ```
        git commit -m "feat: add payment validation logic" -m "- Validates card type and expiry" -m "- Adds unit tests for edge cases" -m "Related to T123 in PRD"
        ```
  3. Once all the subtasks are marked completed and changes have been committed, mark the **parent task** as completed.
- Stop after each sub‑task and wait for the user's go‑ahead.

### Task List Maintenance

1. **Update the task list as you work:**
   - Mark tasks and subtasks as completed (`[x]`) per the protocol above.
   - Add new tasks as they emerge.

2. **Maintain the "Relevant Files" section:**
   - List every file created or modified.
   - Give each file a one‑line description of its purpose.

### AI Instructions

When working with task lists, the AI must:

1. Regularly update the task list file after finishing any significant work.
2. Follow the completion protocol:
   - Mark each finished **sub‑task** `[x]`.
   - Mark the **parent task** `[x]` once **all** its subtasks are `[x]`.
3. Add newly discovered tasks.
4. Keep "Relevant Files" accurate and up to date.
5. Before starting work, check which sub‑task is next.
6. After implementing a sub‑task, update the file and then pause for user approval.
---

## Dev Shortcuts

### `qnew`
> Adopt all best practices from `.agent.rules.md`.

### `qplan`
> Validate design: minimal diffs, consistent with codebase, uses existing code.

### `qcode`
> Implement with tests. Run language-specific quality gates.

### `qcheck`
> Function/method, test, and code quality review for major changes.

### `qcheckf`
> Function/method-level quality review only.

### `qcheckt`
> Test-only quality review.

### `qux`
> UX scenarios list for human QA.

### `qgit`
> Make sure git is configured, ask the  use to configure it before continuing 
> Add, commit (Conventional Commit format), and push.  
> Avoid mentioning Claude or Anthropic.

### `qdocs`
> Update all documentation following Documentation rules (D-1 through D-5):
> - Ensure `/docs` directory exists with system architecture
> - Update/create mermaid diagrams in `/docs/system-architecture.md`
> - Update README with links to documentation
> - Update CLAUDE.md if present
> - Keep all docs in sync with current implementation

### `qprd`
> Generate a Product Requirements Document (PRD) following the PRD generation process:
> - Ask clarifying questions to understand the feature
> - Generate structured PRD with all required sections
> - Save as `prd-[feature-name].md` in `/tasks/` directory
---

---

## While Coding (TypeScript-Specific)

- **C-TS1 (SHOULD NOT)** Use `class` when small testable functions suffice.
- **C-TS2 (SHOULD)** Prefer pure, composable, and testable functions.
- **C-TS3 (MUST)** Use **branded types** for identifiers:
  ```ts
  type UserId = Brand<string, 'UserId'>   // ✅ Good
  type UserId = string                    // ❌ Bad
  ```
- **C-TS4 (MUST)** Use `import type` for type-only imports:
  ```ts
  import type { User } from './types';
  ```
- **C-TS5 (SHOULD)** Use `type` by default; prefer `interface` only for readability or declaration merging.
---

## Testing (TypeScript-Specific)

- **T-TS1 (MUST)** Colocate unit tests with source using `*.spec.ts` files.
- **T-TS2 (MUST)** For API changes, extend tests under `packages/api/test/*.spec.ts`.
- **T-TS3 (SHOULD)** Use holistic assertions:
  ```ts
  expect(result).toEqual([value]); // ✅
  // ❌ Avoid breaking assertions into multiple lines:
  // expect(result).toHaveLength(1);
  // expect(result[0]).toBe(value);
  ```

- **T-TS4 (SHOULD)** Assert domain invariants using `fast-check`:
  ```ts
  import fc from 'fast-check';
  
  describe('getCharacterCount', () => {
    test('is additive', () => {
      fc.assert(
        fc.property(fc.string(), fc.string(), (a, b) => {
          return getCharacterCount(a + b) === getCharacterCount(a) + getCharacterCount(b);
        })
      );
    });
  });
  ```
- **T-TS5 (SHOULD)** Group tests under `describe(functionName, () => …)`.
- **T-TS6 (SHOULD)** Use `expect.any(...)` for flexible types (e.g. UUIDs).
- **T-TS7 (SHOULD NOT)** Test things the TypeScript compiler already enforces (e.g., types).
---

## Database (TypeScript-Specific)

- **D-TS1 (MUST)** Type DB functions as `KyselyDatabase | Transaction<Database>` to ensure compatibility across transactions.
- **D-TS2 (SHOULD)** Override incorrect types in `packages/shared/src/db-types.override.ts`.
---

## Code Organization (TypeScript-Specific)

- **O-TS1 (MUST)** Only add to `packages/shared` if used by ≥ 2 packages.
---

## Tooling Gates (TypeScript-Specific)

- **G-TS1 (MUST)** Pass `prettier --check`.
- **G-TS2 (MUST)** Pass `turbo typecheck lint` (includes `tsc`, `eslint`, and typegen).

Example scripts in `package.json`:
```json
{
  "scripts": {
    "lint": "eslint . --ext .ts,.tsx",
    "typecheck": "tsc --noEmit",
    "format": "prettier --write .",
    "check": "prettier --check .",
    "test": "vitest run"
  }
}
```
---

## TypeScript Test Quality Specifics

- **TQ-TS1 (SHOULD NOT)** Use `@ts-expect-error` to bypass lint rules.
- **TQ-TS2 (SHOULD)** Use strong assertions (`toEqual`, not `toBeGreaterThan`).
---

## Codebase Structure

```text
packages/
  ├── api/                  # Fastify server
  │   └── src/publisher/    # Platform-specific integrations
  ├── api-schema/           # Shared contracts (TypeBox)
  ├── shared/               # Utilities and types used by ≥2 packages
  │   └── social.ts         # Domain-specific logic (e.g., char count)
  └── web/                  # Next.js 15 app with App Router
```
---

